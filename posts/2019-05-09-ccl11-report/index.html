<!doctype html><html lang=en-us><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge,chrome=1"><title>11th Choreographic Coding Lab | CCOnline</title><meta name=viewport content="width=device-width,minimum-scale=1"><meta name=generator content="Hugo 0.74.3"><meta name=ROBOTS content="NOINDEX, NOFOLLOW"><link href=/dist/css/app.4fc0b62e4b82c997bb0041217cd6b979.css rel=stylesheet><meta property="og:title" content="11th Choreographic Coding Lab"><meta property="og:description" content="report"><meta property="og:type" content="article"><meta property="og:url" content="https://cconline.naotohieda.com/posts/2019-05-09-ccl11-report/"><meta property="article:published_time" content="2019-05-09T00:00:00+00:00"><meta property="article:modified_time" content="2019-05-09T00:00:00+00:00"><meta itemprop=name content="11th Choreographic Coding Lab"><meta itemprop=description content="report"><meta itemprop=datePublished content="2019-05-09T00:00:00+00:00"><meta itemprop=dateModified content="2019-05-09T00:00:00+00:00"><meta itemprop=wordCount content="708"><meta itemprop=keywords content="report,ccl,"><meta name=twitter:card content="summary"><meta name=twitter:title content="11th Choreographic Coding Lab"><meta name=twitter:description content="report"></head><body class="ma0 avenir bg-near-white"><header><div class=bg-black><nav class="pv3 ph3 ph4-ns" role=navigation><div class="flex-l justify-between items-center center"><a href=/ class="f3 fw2 hover-white no-underline white-90 dib">CCOnline</a><div class="flex-l items-center"></div></div></nav></div></header><main class=pb7 role=main><article class="flex-l flex-wrap justify-between mw8 center ph3"><header class="mt4 w-100"><aside class="instapaper_ignoref b helvetica tracked">POSTS</aside><div id=sharing class=mt3><a href="https://www.facebook.com/sharer.php?u=https://cconline.naotohieda.com/posts/2019-05-09-ccl11-report/" class="facebook no-underline" aria-label="share on Facebook"><svg height="32" style="enable-background:new 0 0 67 67" viewBox="0 0 67 67" width="32" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M28.765 50.32h6.744V33.998h4.499l.596-5.624h-5.095l.007-2.816c0-1.466.14-2.253 2.244-2.253h2.812V17.68h-4.5c-5.405.0-7.307 2.729-7.307 7.317v3.377h-3.369v5.625h3.369V50.32zM33 64C16.432 64 3 50.569 3 34S16.432 4 33 4s30 13.431 30 30S49.568 64 33 64z" style="fill-rule:evenodd;clip-rule:evenodd"/></svg></a><a href="https://twitter.com/share?url=https://cconline.naotohieda.com/posts/2019-05-09-ccl11-report/&text=11th%20Choreographic%20Coding%20Lab" class="twitter no-underline" aria-label="share on Twitter"><svg height="32" style="enable-background:new 0 0 67 67" viewBox="0 0 67 67" width="32" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M37.167 22.283c-2.619.953-4.274 3.411-4.086 6.101l.063 1.038-1.048-.127c-3.813-.487-7.145-2.139-9.974-4.915l-1.383-1.377-.356 1.017c-.754 2.267-.272 4.661 1.299 6.271.838.89.649 1.017-.796.487-.503-.169-.943-.296-.985-.233-.146.149.356 2.076.754 2.839.545 1.06 1.655 2.097 2.871 2.712l1.027.487-1.215.021c-1.173.0-1.215.021-1.089.467.419 1.377 2.074 2.839 3.918 3.475l1.299.444-1.131.678c-1.676.976-3.646 1.526-5.616 1.568C19.775 43.256 19 43.341 19 43.405c0 .211 2.557 1.397 4.044 1.864 4.463 1.377 9.765.783 13.746-1.568 2.829-1.673 5.657-5 6.978-8.221.713-1.716 1.425-4.851 1.425-6.354.0-.975.063-1.102 1.236-2.267.692-.678 1.341-1.419 1.467-1.631.21-.403.188-.403-.88-.043-1.781.636-2.033.551-1.152-.402.649-.678 1.425-1.907 1.425-2.267.0-.063-.314.042-.671.233-.377.212-1.215.53-1.844.72l-1.131.361-1.027-.7c-.566-.381-1.361-.805-1.781-.932C39.766 21.902 38.131 21.944 37.167 22.283zM33 64C16.432 64 3 50.569 3 34S16.432 4 33 4s30 13.431 30 30S49.568 64 33 64z" style="fill-rule:evenodd;clip-rule:evenodd;fill:"/></svg></a><a href="https://www.linkedin.com/shareArticle?mini=true&url=https://cconline.naotohieda.com/posts/2019-05-09-ccl11-report/&title=11th%20Choreographic%20Coding%20Lab" class="linkedin no-underline" aria-label="share on LinkedIn"><svg height="32" style="enable-background:new 0 0 65 65" viewBox="0 0 65 65" width="32" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M50.837 48.137V36.425c0-6.275-3.35-9.195-7.816-9.195-3.604.0-5.219 1.983-6.119 3.374V27.71h-6.79c.09 1.917.0 20.427.0 20.427h6.79V36.729c0-.609.044-1.219.224-1.655.49-1.22 1.607-2.483 3.482-2.483 2.458.0 3.44 1.873 3.44 4.618v10.929H50.837zM22.959 24.922c2.367.0 3.842-1.57 3.842-3.531-.044-2.003-1.475-3.528-3.797-3.528s-3.841 1.524-3.841 3.528c0 1.961 1.474 3.531 3.753 3.531H22.959zM34 64C17.432 64 4 50.568 4 34 4 17.431 17.432 4 34 4s30 13.431 30 30C64 50.568 50.568 64 34 64zM26.354 48.137V27.71h-6.789v20.427H26.354z" style="fill-rule:evenodd;clip-rule:evenodd;fill:"/></svg></a></div><h1 class="f1 athelas mt3 mb1">11th Choreographic Coding Lab</h1><p class=tracked>By <strong>Naoto Hieda</strong></p><time class="f6 mv4 dib tracked" datetime=2019-05-09T00:00:00Z>May 9, 2019</time></header><div class="nested-copy-line-height lh-copy serif f4 nested-links nested-img mid-gray pr4-l w-two-thirds-l"><p>The 11th Choreographic Coding Lab (CCL) organized by Motion Bank took place at Kunsthalle Mainz (Mainz, Germany) from April 28th to May 2nd, 2019. It was my third participation in CCLs; the first time was in New York in 2015, where I used Deborah Hay dataset to move a plotter. The second time was in Amsterdam in 2017, where various collaborations emerged; notably, Lads with Chris Matthews and the second iteration of Pathfinder with Mio Loclair, which became a single day workshop in Bucharest called CCL+Pathfinder during the NOVA Festival at Point theater in 2018.</p><p>In this edition of CCL, Florian Jenett and Anton Koch from Motion Bank made a new tool as a spin-off of PieceMaker, which is a platform for dance data recording and annotation. They made a player application called Effect Data Player that streams motion capture data of “Effect” choreographed by Taneli Törmä, which is the main piece for the exhibition “Between Us” at Kunsthalle. PieceMaker handles various data structures such as videos, annotations and motion capture data, but the downside is that it is not suitable for rapid prototyping because of its complexity. On the other hand, the new Effect player is a dedicated application for streaming motion data through OSC (Open Sound Control) or Websocket, which is easily accessible from frameworks such as Processing and HTML5.</p><p><img src=/images/2019-05-09-ccl11-effect.png alt></p><p>This enabled many of us to work on the dataset and during the presentation we could see transformation of the dance data into visual and sound. It also helped that the traces of the dance piece are geometric so that we were not using the movement data as a random data stream. We shared a clear idea that we were extracting the choreography from body movements and expressing in other mediums. These movements were abstracted and no longer embodied, or re-embodied in a way that is not intended in the original dance piece.</p><p><img src=/images/2019-05-09-ccl11-mazetools.jpg alt></p><p>During the week, I spent most of the time with <a href="https://tristanschulze.de/?page_id=2615">Tristan Schulze</a> and his students <a href=https://www.mazetools.com/>Stephan</a> and Katja; I contacted him after discovering his algorithmic tapestry series at Kindl (Berlin), and while we had a coffee meeting, we planed an “excursion” to CCL together. At CCL, Tristan worked on a sound piece that is reactive to the dancers. I was observing his creation process and Erica, Alvin, Sonja and Abi choreographing for the system as well as recording movement data with the <a href=http://thecaptury.com/>Captury</a> system, which is a markerless tracking using color cameras and a machine learning algorithm similar to <a href=https://medium.com/tensorflow/real-time-human-pose-estimation-in-the-browser-with-tensorflow-js-7dd0bc881cd5>PoseNet</a>. Unfortunately, they could not have live data stream by the presentation; instead, they work on recorded or offline data, and I think this made the choreographic process even more interesting. The dancers had to imagine how the sound would react to the movements without experiencing the reactive system. The process looked as if the dancers are coding through the choreography — unlike a conventional geometric choreography but rather like a simulation of a complex phenomenon, which is an interesting topic for further collaborations of media artists and dancers in a conceptual level.</p><p><img src=/images/2019-05-09-ccl11-erica.jpg alt></p><p>As for my project, I started working on the idea of digitizing movement snippets and associating the movements to texts or 3D shapes. I am interested in translation of one modality to another; for instance, how words can be related to gestures or images, and how it is influenced by different perspectives (e.g., culture, gender or neurodiversity). At the moment, I focus on my perceptions, which I am most familiar with. As opposed to Motion Bank’s PieceMaker platform, which is intended to record a full dance piece (or its rehearsal) and to make annotations, my intention is to record short video clips of movements, which can be tagged with words, colors or even a Processing sketch, and potentially remix this movement vocabulary to create totally another piece. I am refining the tool as a web version, and hopefully, I can share next iterations online soon.</p><p><img src=/images/2019-05-09-ccl11-naoto.png alt></p><p>Huge thanks to the Motion Bank team for organizing the event and providing software and equipment; Marc Downie, Maria Judova, Constantine Nisidis, Liam Blackburn and Jean-Philippe Rivière for artistic and scientific inputs; Erica and Alvin for a warm-up session; Alexander Trattler for a TouchDesigner workshop; and all the participants for making such an amazing event together.</p><ul class=pa0><li class=list><a href=/tags/report class="link f5 grow no-underline br-pill ba ph3 pv2 mb2 dib black sans-serif">report</a></li><li class=list><a href=/tags/ccl class="link f5 grow no-underline br-pill ba ph3 pv2 mb2 dib black sans-serif">ccl</a></li></ul><div class="mt6 instapaper_ignoref"></div></div><aside class="w-30-l mt6-l"><div class="bg-light-gray pa3 nested-list-reset nested-copy-line-height nested-links"><p class="f5 b mb3">Related</p><ul class="pa0 list"><li class=mb2><a href=/posts/2018-05-03-ccl-pathfinder/>NOVA: Choreographic Coding Lab + Pathfinder</a></li><li class=mb2><a href=/posts/2017-05-10-ccl8-choreographic-thinking/>CCL8: Choreographic Thinking Input</a></li><li class=mb2><a href=/posts/2015-09-19-12-dimensions-of-movement/>12 dimensions of movement</a></li><li class=mb2><a href=/posts/2015-09-19-ccl5-choreographic-thinking/>CCL5: Choreographic Thinking Input</a></li><li class=mb2><a href=/posts/2015-08-31-ccl4-choreographic-thinking/>CCL4: Choreographic Thinking Input</a></li><li class=mb2><a href=/posts/2015-08-31-ccl4-trackable-qualities/>CCL4: Trackable Qualities</a></li></ul></div></aside></article></main><footer class="bg-black bottom-0 w-100 pa3" role=contentinfo><div class="flex justify-between"><a class="f4 fw4 hover-white no-underline white-70 dn dib-ns pv2 ph3" href=https://cconline.naotohieda.com/>&copy; CCOnline 2020</a><div></div></div></footer><script src=/dist/js/app.3fc0f988d21662902933.js></script></body></html>